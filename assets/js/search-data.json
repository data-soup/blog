{
  
    
        "post0": {
            "title": "Overview of One Year of Lottery Ticket Research",
            "content": "Winning tickets were discovered in March 2018 and presented at ICRL the same year. It drawed a lot of attention. It sheds light on yet unknown underlying properties of neural networks and seems to be one of the keys for faster training and smaller models. Overall flipping on the head how we approach neural net architecture design. . Winning tickets in deep learning were mentioned as one of the most important topics of 2019 by Lex Fridman’s in his Deep Learning State of the Art 2020 (awesome) lecture: . This article aims at summarizing what I understood after reading about it. Hope you’ll enjoy it. TLDR below. . Pruning . It is known that DL models have generally heavy computational requirements and can be blocking in particular settings. ResNet, for instance, requires 50M operations for one single inference. They’ve been efforts to reduce the number of parameters with quantization, knowledge distillation and pruning. . Pruning removes the least important weights or channels. Least important can mean the one with the smallest magnitudes or other heuristics. Such a technique is working well and can reduce up to 90% of the weights in a network while preserving most of the original accuracy. While pruning can help to reduce the model’s size, it won’t help training it faster. It is generally a post-processing step, after training. Retraining a pruned model won’t yield the same results as if you prune after training. If it were possible to be able to train the pruned model directly, train faster without sacrificing performances. . But in their paper Jonathan Frankle, Michael Carbin experimentally found that instead of training large networks and then reduce their size we might be able to train smaller networks upfront: . dense, randomly-initialized, feed-forward networks contain subnetworks (“winning tickets”) that - when trained in isolation - reach test accuracy comparable to the original network in a similar number of iterations. . . Winning Tickets . In order to find winning tickets, initialization seems to be the key: . When their parameters are randomly reinitialized […], our winning tickets no longer match the performance of the original network, offering evidence that these smaller networks do not train effectively unless they are appropriately initialized. . They found that we can train a pruned model again after re-initializing the weights with the original model’s parameters. This gives systematically better results than re-initializing randomly. Doing this process multiple times is called iterative pruning (with no re-init): . 1. Randomly initialize a neural network [with weights θ0] 2. Train the network for j iterations, arriving at parameters θj 3. Prune [by magnitude] p% of the parameters in θj , creating a mask m 4. Reset the remaining parameters to their values in θ0 5. Goto 2 . If the subnetwork produced by this technique matches the original network’s performances, it is called a winning ticket. The following graph represents averaged results of five runs on a LeNet (fully dense) network on the MNIST dataset. This model was pruned in different ways: . [blue] Done with the recipe above | [orange] Same as blue but replace step 4 by “Randomly initialize the remaining parameters” | [red] Same as the orange line without step 5 | [green] Same as blue without step 5 | . . We can see that step 4 is the key as the green and blue lines are consistently performing better and are trained faster than randomly re-initialized networks. They also found similar results with convolutional networks like VGG and ResNet on MNIST and CIFAR10 (there are many more details in the original paper). . . Pruning Early . But the method above seems to struggle against deeper networks. In a follow-up paper (March 2019), the authors changed slightly the way the remaining parameters are reset (step 4): . Rather than set the weights of a winning ticket to their original initializations, we set them to the weights obtained after a small number of training iterations (late resetting). Using late resetting, we identify the first winning tickets for Resnet-50 on Imagenet. . The graph below plot performances against different levels of sparsity of deep models rewound (iteration at which we reset the weights) with different values. We can see that rewinding at iteration 0 does not perform better than the original network whereas rewinding at higher iteration does: . . Those deeper models were resisting the winning ticket recipe above but found something interesting after looking at their stability: . Stability to pruning: “the distance between the weights of a subnetwork trained in isolation and the weights of the same subnetwork when trained within the larger network”. Which captures “a subnetwork’s ability to train in isolation and still reach the same destination as the larger network”. If a neuron is stable it won’t be much affected by its neighbors disappearing through masking. | Stability to data order: “the distance between the weights of two copies of a subnetwork trained with different data orders”. Which captures “ a subnetwork’s intrinsic ability to consistently reach the same destination despite the gradient noise of SGD”. | . The table below shows stability for different networks. Warmup means that the learning rate is scheduled to increase slowly during training, possibly reducing the noise of the optimizer. IMP is the original recipe to generate winning tickets: . . We can see that IMP fails at fiding winning tickets in deeper networks without changing the learning rate. We can also see that there’s a link between performances and the stabilities measures. “Winning tickets are more stable than the random subnetworks”. . . What about other domains? . So far winning tickets have been tested on the same datasets and on computer vision tasks. One can ask if this isn’t just drastic overfitting or if the winning tickets transfer at all. . Facebook published a paper (June 2019) tested the winning ticket evaluation and transfer across six visual datasets. For instance, testing generating winning tickets on ImageNet and testing it others (like CIFAR-100): . . They observed that winning tickets generalize across all datasets with (at least) close performances than the original one. And that winning tickets generated on larger datasets generalized better than the other ones, probably due to the number of classes in the original model. Finally, this paper also tested the transfer successfully across different optimizers successfully. . What about other tasks than image classification? Facebook published in parallel a paper (June 2019) that test the winning ticket in reinforcement learning and NLP tasks. . For NLP, we found that winning ticket initializations beat random tickets both for recurrent LSTM models trained on language modeling and Transformer models trained on machine translation. […] For RL, we found that winning ticket initializations substantially outperformed random tickets on classic control problems and for many, but not all, Atari games. . . TLDR . Many neural networks are over-parameterized | Frankle &amp; Carbin found simple algorithm to find smaller network within larger ones | Those sub-networks are trainable from scratch and can perform at least as well and often better | What makes winning tickets special is still unclear but seems to be a critical step toward a deeper understanding of the underlying properties of neural nets | . . Sources . The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks | Stabilizing the Lottery Ticket Hypothesis | One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers | Playing the lottery with rewards and multiple languages: lottery tickets in RL and NLP | .",
            "url": "https://data-soup.github.io/blog/2020/02/13/winning-ticket-overview.html",
            "relUrl": "/2020/02/13/winning-ticket-overview.html",
            "date": " • Feb 13, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Paper Summary: Unsupervised learning by competing hidden units",
            "content": "This is a summary of Unsupervised learning by competing hidden units. TLDR below. . Author Organization Previous work . Dmitry Krotov | MIT, IBM (Watson, Research), Princeton | Dense Associative Memory Is Robust to Adversarial Inputs | . John J. Hopfield | Princeton Neuroscience Institute | same | . . This paper introduces a novel unsupervised learning technique. There’s (almost) no backprop and the model isn’t trained for a particular task. The two authors, coming from neuroscience and computer science backgrounds based this work on two biological observations: . 1- Synapses changes are local: . In biology, the synapse update depends on the activities of the presynaptic cell and the postsynaptic cell and perhaps on some global variables such as how well the task was carried out. (page 1) . The weight of a cell between A and B trained with backpropagation not only depends on the activity of A and B but also on the previous layer’s activity and the training labels. So it doesn’t depend on A, B activity but other potentially any other neurons in the network. This is inspired by Hebb’s idea. . 2- Animals learn without labeled data and fewer data than neural networks trained with backpropagation: . Second, higher animals require extensive sensory experience to tune the early […] visual system into an adult system. This experience is believed to be predominantly observational, with few or no labels, so that there is no explicit task. (page 1) . Unsupervised local training . Authors managed to train their model on MNIST and CIFAR-10 with only forward passes, meaning: . This technique is less computationally demanding, its computational complexity is comparable to the computational complexity of the forward pass in backpropagation (source). | Doesn’t require to train the model on a given task to make meaningful representation from the data. | . The blue rectangles are the authors “biological learning algorithm”. First, the data is going through it, without any label or any indication on the task it’ll be used for. Once trained a fully connected network is appended on top of it in order to specialize the model and make the desired predictions. This part is trained using backpropagation. . . Usually to compute the activity of the hidden layer hμ, we project the input vi on it by multiplying it with a matrix Wμi and then apply non-linearity. In this new technique the hμ activity is computed solving this differential equation: . . μ is the index of the hidden layer we want to update | τ is a timescale of the process | Iμ is the input current | The second term, the sum of all other hidden layers, introduce competition between neurons. Stronger units will inhibit weaker ones. Without it, all neurons will fire activation when input is shown. Note that this term introduces lateral connections between units since they units within the same layer can be connected to each other. | r is a ReLU and winh is a hyperparameter constant. | . Since training is local and requires only forward passes, this architecture is different from an auto-encoder. . In action . In an experiment on MNIST and CIFAR-10, the authors trained 2000 hidden units using their biological technique to find the matrix Wμi: . Hidden units were initialized with a normal distribution | Hidden units are trained (again, without explicit task or labels) | Those units are then frozen and plugged to a perceptron | The perceptron weights were trained using SGD | . The training error on MNIST can be seen in the rightmost figure of the image below (BP stands for backpropagation and BIO for the proposed approach). We can see that despite a higher training error, the testing error is very close to the model trained end-to-end. . . On MNIST, we can see that the features learned by the proposed biological learning algorithm (left figure) are different from the one trained with backpropagation (middle figure). . the network learns a distributed representation of the data over multiple hidden units. This representation, however, is very different from the representation learned by the network trained end-to-end, as is clear from comparison of Fig. 3, Left and Center. . Similarly for CIFAR-10: . . . TLDR . no top–down propagation of information, the synaptic weights are learned using only bottom-up signals, and the algorithm is agnostic about the task that the network will have to solve eventually in the top layer (page 8) . | A new unsupervised training technique, where the task isn’t defined, the training set goes through the model and is trained without backpropagation. A fully connected perceptron is appended on top, trained with backpropagation with the lower unsupervised submodel is frozen. | This technique shows poorer but near state of the art generalizations performances on MNIST and CIFAR. | There’s no forward/backward passes, each cell is potentially connected to every other, including on its own layer. | . . Complementary resources: . Video presentation by one of the authors at MIT. | Github for reproduction. | Blog post on IBM’s blog. | .",
            "url": "https://data-soup.github.io/blog/2019/06/17/unsupervised-learning-competing-hidden-units.html",
            "relUrl": "/2019/06/17/unsupervised-learning-competing-hidden-units.html",
            "date": " • Jun 17, 2019"
        }
        
    
  
    
        ,"post2": {
            "title": "Paper Summary: Stiffness, A New Perspective on Generalization in Neural Networks",
            "content": "This is a summary of Stiffness: A New Perspective on Generalization in Neural Networks. TLDR below. . Author Organization Previous work . Stanislav Fort | Google AI Resident, Google AI Zurich | The Goldilocks zone: Towards better understanding of neural network loss landscapes | . Paweł Krzysztof Nowak | Google AI Resident |   | . Srini Narayanan | Google AI Resident | Points, Paths, and Playscapes: Large-scale Spatial Language Understanding Tasks Set in the Real World | . . Stiffness? . This paper aims at improving our understanding of how neural networks generalize from the point of view of stiffness. The intuition behind stiffness is how a gradient update on one point affects another: . [it] characterizes the amount of correlation between changes in loss on the two due to the application of a gradient update based on one of them. (4.1, Results and discussion) . Stiffness is expressed as the expected sign of the gradients g: . . A weight update that improves the loss for X_1 and X_2 is stiff and characterized as anti-stiff if the loss beneficiate for one of the points and doesn’t help the other. . . The question is now how do we choose X_1 and X_2. Authors explore two ways: by class membership or by distance. . Stiffness based on class membership . We can look at how a gradient update on a point in class A will affect another point’s loss belonging to class B. In the paper they craft a class stiffness matrix, which is the average of stiffness between each point grouped by class: . . The diagonal of this matrix represent the model’s within class generalization capability. You can find an example of stiffness class matrix at different steps of the training stage: . . At early stages, the stiffness is high between members of the same classes (hence the red diagonal). The majority of the cells raises their stiffness until reaching the point of overfitting: stiffness reaches 0. . Stiffness as a function distance and learning rate . Stiffness is then studied through the distance lens, they distinguish two kinds of distance: pixel-wise (in the input space) and layerwise (in the representational space). . . The general pattern visible in Figure 9 is that there exists a critical distance within which input data points tend to move together under gradient updates, i.e. have positive stiffness. This holds true for all layers in the network, with the tendency of deeper layers to have smaller stiff domain sizes. . Authors define stiff regions as “regions of the data space that move together when a gradient update is applied”. . . We can see that a higher learning rate increase the size of the stiff regions which suggests that higher learning rates help generalization. . . TLDR . Stiffness quantify how much gradient update on one group of point affects another | Stiffness is tightly linked to generalization | Stiffness tends to 0 when the system overfit | Higher learning rate increases the area under which points are moving together | . . Complementary resources: . Manifold Mixup: Better Representations by Interpolating Hidden States - https://arxiv.org/abs/1806.05236 (cited in the article) | .",
            "url": "https://data-soup.github.io/blog/2019/03/28/stiffness-new-perspecive-generalization.html",
            "relUrl": "/2019/03/28/stiffness-new-perspecive-generalization.html",
            "date": " • Mar 28, 2019"
        }
        
    
  
    
        ,"post3": {
            "title": "What is Knowledge Distillation?",
            "content": "Knowledge distillation is a fascinating concept, we’ll cover briefly why we need it, how it works. . Weight Matters . Today’s models can be quite large, here are some of the top models for the ImageNet dataset: . Model Weights (millions) Size (32-bits floats) Size (16-bits floats) . MobileNet-224 | 4.3 | 17.2 Mo | 8.6 Mo | . VGG16 | 143.7 | 574.8 Mo | 287.4 Mo | . InceptionV3 | 23.9 | 95.6 Mo | 47.8 Mo | . ResNet-50 | 25.6 | 102.4 Mo | 51.2 Mo | . InceptionResNetV2 | 55.9 | 223.6 Mo | 111.8 Mo | . The models were instantiated via keras.applications module with top layers, the number of parameters are given by summary(). . It seems fair to say that simple computer vision models weigh easily ~100Mo. A hundred Mo just to be able to make an inference isn’t a viable solution for an end product. A remote API can do the trick, but now your product needs to add encryption, you need to store and upload data, the user needs to have a reliable internet connection to have a decent speed. We can train a narrower network, they’ll probably fit in a small memory. But chances are they won’t be good enough at extracting complex features. . And we’re not talking about ensembles. Ensembles are a great way to extract a lot of knowledge from the training data. But at test time it can be too expensive to run a hundred different models in parallel. The knowledge per parameter ratio is quite low. . In the end a model can have great score at training time, but we might want to: lower its size (for embedded systems), increase inference speed or simply reduce complexity. Geoffrey Hinton talks about reducing its “memory foot print”: . . Many insects have a larval form that is optimized for extracting energy and nutrients from the environment and a completely different adult form that is optimized for the very different requirements of traveling and reproduction. In large-scale machine learning, we typically use very similar models for the training stage and the deployment stage despite their very different requirements (…) (Distilling the Knowledge in a Neural Network) . Training a smaller model from a larger one is called knowledge distillation. . Distillation . The authors continue that we are identifying knowledge with the values of the weights which makes it “hard to see how we can change the form of the model but keep the same knowledge”. And remind us that we can see knowledge as a mapping from input to output. . Knowledge distillation’s goal is to transfer the learning from one performant and heavy teacher to a more compact student. . . To do so, we look at the teacher’s softmax layer, magnify it and the student learns how to produce them. We need to magnify because the softmax layer will smash down to zero the least probable classes and rises close to one the most probable (like one hot vector). We can also keep the relative probabilities between classes, where a motocycle and a bicycle share more similarities on the softmax layer rather than a book. We can do it by raising the temperature T. . . To transfer knowledge, a student is trained on the soften probabilities (T»1) produced by a larger teacher. When the temperature T is smaller than one, the most expected classes will impact the most the final probability. Similarly, when increasing the temperature the probabilities will be softer/flattened across classes -you can have here an intuition of the influence of temperature on a single exp(). . First the teacher’s temperature is increased until a certain point. Then the student is trained to copy its teacher’s soft probabilities. . labrador cow golden retriever moto bike   . 1 | 0 | 0 | 0 | 0 | hard targets | . 0.8 | 10^-5 | 0.2 | 10^-9 | 10^-9 | soft targets (T=1) | . 0.6 | 10^-2 | 0.45 | 10^-4 | 10^-4 | soft targets (T»1) | . Benefits . Training on soft targets has several advantages: more information can be extracted from a single sample, training can be done on fewer examples, no need for labeled data . The softmax of a multi-class classifier will give you higher probabilities for similar images. A rose may have similar soft probabilities with a tulip rather than a labrador. Similarly, two different classes are present in the same image, we might see it on the output. So more information are extracted from each training sample. . This is a consequence from the first point, the model can be trained on fewer training examples than the teacher. The learning is also faster because there are more constraints on the student. It needs to target multiple (soft) outputs rather than a single (hard) one. . Since the student learns from soft targets only, by relative similarities between classes, it can be trained on a unlabelled dataset, using only the master has an on-fly “soft labeler”. But in practice, the dataset can be the same as the teacher. . Loss . Distillation loss is generally in two forms: matching function values, matching derivatives or both, corresponding to a regression problem with different orders: . Matching function values: tries to minimize the difference between the predictions of the teacher and the student. For a classification task, this is done by using classical cross entropy. . | Matching derivatives: tries to match the values and the derivatives. This is a more efficient approach than before because here we can have full access to the teacher and we are able to measure the impacts of small variations in its inputs. . | . We can also try to increase the influence of the prediction by adding directly the hard loss: . alpha ~= 0.1 KD_loss = alpha * log_loss(y_true, softmax(logits)) + logloss(y_true, softmax(logits/temperature)) . You can see a cool implementation here. . Resources . TTIC Geoffrey Hilton - Dark Knowledge - presentation by the author of the first Knowledge Distillation paper . | IEE Security Symposium, Papernot: Note that the distillation as a counter measure for adversarial examples has been proven to be not effective anymore. . | .",
            "url": "https://data-soup.github.io/blog/2018/11/22/knowledge-distillation.html",
            "relUrl": "/2018/11/22/knowledge-distillation.html",
            "date": " • Nov 22, 2018"
        }
        
    
  
    
        ,"post4": {
            "title": "Adversarial Resnet50",
            "content": "Inspired from M.Pedersen&#39;s tutorial (also in video), this time using Keras and ResNet50. . We can first import a ResNet50 pre-trained model. . from keras.applications.resnet50 import ResNet50 model = ResNet50(weights=&#39;imagenet&#39;, include_top=True) . Using TensorFlow backend. . Importing class names from ResNet50&#39;s object . from keras.applications import imagenet_utils from keras.utils.data_utils import get_file import json def get_imagenet_classes(): CLASS_INDEX_PATH = &#39;https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json&#39; fpath = get_file(&#39;imagenet_class_index.json&#39;, CLASS_INDEX_PATH, file_hash=&#39;c2c37ea517e94d9795004a39431a14cb&#39;) with open(fpath) as f: return [values[1] for key, values in json.load(f).items()] class_indexes = get_imagenet_classes() . Few helper functions to: load, pre-process, print top n prediction and get a specific class prediction . from keras.preprocessing import image as image_ from keras.applications.resnet50 import preprocess_input, decode_predictions import numpy as np from PIL import Image def load_image(image_path=None, image_url=None, new_size=None): if(image_path is not None): img = image.load_img(image_path, target_size=new_size) elif(image_url is not None): from PIL import Image import requests import urllib.request from io import BytesIO fd = urllib.request.urlretrieve(image_url, &quot;tmp.jpg&quot;) im1 = Image.open(&quot;tmp.jpg&quot;) img = im1.resize(new_size, Image.ANTIALIAS) return img def process_image(image): x = np.expand_dims(image_.img_to_array(image), axis=0) x = preprocess_input(x, data_format=None, mode=&#39;caffe&#39;) return x def get_predictions(predictions, top=3): if(top is 1): return decode_predictions(predictions, top=1)[0][0][1:] else: return decode_predictions(predictions, top=top)[0] def get_class_probability(predictions, target_name, class_names=class_indexes): try: index = class_names.index(target_name) return predictions[0][index] except ValueError: return None def rebuild_image(x_, as_np_array=False): x = x_.copy() mean = [103.939, 116.779, 123.68] x[..., 0] += mean[0] x[..., 1] += mean[1] x[..., 2] += mean[2] x = x[..., ::-1] x = x.astype(np.uint16) if(as_np_array): return x else: return image_.array_to_img(x) . Downloading an image. I choose three differents images: . One with strong components in the red and blue component: a frog | One with some white pixels (ie, RGB=(255,255,255)): alpe mountain | One random: a dog | . import matplotlib.pyplot as plt url_snow = &#39;https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Finsteraarhorn_and_surrounding_mounts.jpg/1280px-Finsteraarhorn_and_surrounding_mounts.jpg&#39; url_blue_green_frog = &#39;http://1papernews.xyz/wp-content/uploads/2017/02/1-6-592x370.jpg&#39; url_dog = &quot;https://i2.wp.com/manipulatori.cz/wp-content/uploads/2016/05/dog-1210559_960_720.jpg?w=960&quot; frog = load_image(image_url= url_blue_green_frog, new_size=(224, 224)) dog = load_image(image_url= url_dog, new_size=(224, 224)) snow = load_image(image_url= url_snow, new_size=(224, 224)) plt.figure(1) plt.subplot(131) plt.imshow(snow) plt.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, bottom=&#39;off&#39;, top=&#39;off&#39;, labelbottom=&#39;off&#39;, right=&#39;off&#39;, left=&#39;off&#39;, labelleft=&#39;off&#39;) plt.grid(False) plt.subplot(132) plt.imshow(dog) plt.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, bottom=&#39;off&#39;, top=&#39;off&#39;, labelbottom=&#39;off&#39;, right=&#39;off&#39;, left=&#39;off&#39;, labelleft=&#39;off&#39;) plt.grid(False) plt.subplot(133) plt.imshow(frog) plt.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, bottom=&#39;off&#39;, top=&#39;off&#39;, labelbottom=&#39;off&#39;, right=&#39;off&#39;, left=&#39;off&#39;, labelleft=&#39;off&#39;) plt.grid(False) . target_class = &quot;plane&quot; def basic_predictions(model, image, target_class): processed_image = process_image(image) predictions = model.predict(processed_image) original_prediction = get_predictions(predictions, top=1) target_class_prediction = get_class_probability(predictions, target_class) info = &quot;Image recognised as a(n) {0} with confidence {1:.2}, &quot; &quot;target class {2} with confidence {3:.2}&quot; print(info.format(original_prediction[0], original_prediction[1], target_class, target_class_prediction)) basic_predictions(model, frog, target_class) basic_predictions(model, dog, target_class) basic_predictions(model, snow, target_class) . Image recognised as a(n) tailed_frog with confidence 0.85, target class plane with confidence 1.3e-08 Image recognised as a(n) golden_retriever with confidence 0.81, target class plane with confidence 2.6e-07 Image recognised as a(n) alp with confidence 0.93, target class plane with confidence 1.2e-08 . Generating adversarial noise . def plot_image_only(ax, image, title=&#39;&#39;): ax.imshow(image) ax.grid(False) ax.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, bottom=&#39;off&#39;, top=&#39;off&#39;, labelbottom=&#39;off&#39;, right=&#39;off&#39;, left=&#39;off&#39;, labelleft=&#39;off&#39;) ax.set_title(title) def plot_adversarial(model, adversarial_image, added_noise, original_image, amplify_noise = 10, process_image=process_image): title = &quot;image {0} (confidence score: {1:.4})&quot; fig = plt.figure(figsize=(12,12)) ax = fig.add_subplot(221) original_prediction = get_predictions(model.predict(process_image(original_image)), top=1) plot_image_only(ax, original_image, (&quot;Original &quot;+title).format(original_prediction[0], original_prediction[1])) ax = fig.add_subplot(222) noise = rebuild_image((added_noise[0] - added_noise[0].min()) * amplify_noise) plot_image_only(ax, noise, &quot;Amplified noise (x{0})&quot;.format(amplify_noise)) ax = fig.add_subplot(223) adversarial_prediction = get_predictions(model.predict(adversarial_image), top=1) adversarial = rebuild_image(adversarial_image[0]) plot_image_only(ax, adversarial, (&quot;Adversarial &quot;+title).format(adversarial_prediction[0], adversarial_prediction[1])) . from keras import backend as K # got some code from this great post on medium.com/@ageitgey/machine-learning-is-fun-part-8-how-to-intentionally-trick-neural-networks-b55da32b7196 def find_adversial_image(model, target_class, image, minimal_cost=0.8, noise_clip=(-3,3), factor_step=5, log_progression=True, max_iteration=500, plot_result_function=plot_adversarial, plot_result=True): model_output_layer = model.layers[-1].output model_input_layer = model.layers[0].input target_class_id = class_indexes.index(target_class) cost_function = model_output_layer[0, target_class_id] gradient_input_output = K.gradients(cost_function, model_input_layer)[0] get_cost_gradient = K.function([model_input_layer, K.learning_phase()], [cost_function, gradient_input_output]) log = &quot;#{0} predicted likelihood for {2} is {1:.4}%&quot; noise = np.zeros(process_image(image).shape) np_image = image_.img_to_array(image) for i in range(max_iteration): noisy_image = np.clip(np_image + noise[0], 0, 255) noisy_image = process_image(noisy_image) cost, gradients = get_cost_gradient([noisy_image, 0]) if(cost &gt;= minimal_cost): print(&quot;break@&quot;, log.format(i, cost * 100, target_class)) break if(log_progression and i % 15 == 0): print(log.format(i, cost * 100, target_class)) grad_absmax = np.abs(gradients).max() if grad_absmax &lt; 1e-10: grad_absmax = 1e-10 step_size = factor_step / grad_absmax noise += gradients * step_size noise = np.clip(noise, noise_clip[0], noise_clip[1]) if(plot_result): plot_result_function(model, noisy_image, noise, image) return noisy_image, noise, image . correction . _,_,_, = find_adversial_image(model=model, image=dog, target_class=target_class, minimal_cost=0.99) . #0 predicted likelihood for plane is 2.573e-05% #15 predicted likelihood for plane is 7.962% break@ #27 predicted likelihood for plane is 99.06% . _,_,_, = find_adversial_image(model=model, image=snow, target_class=target_class, minimal_cost=0.99) . #0 predicted likelihood for plane is 1.194e-06% #15 predicted likelihood for plane is 70.62% break@ #21 predicted likelihood for plane is 99.51% . adversarial_frog, adversarial_noise_frog,_ = find_adversial_image(model=model, image=frog, target_class=target_class, minimal_cost=0.99) . #0 predicted likelihood for plane is 1.332e-06% break@ #15 predicted likelihood for plane is 99.66% . Bonus: we input a black image and choose to target the &#39;banjo&#39; class. . adversarial_frog, adversarial_noise_frog,_ = find_adversial_image(model=model, image=np.zeros((224,224,3)), target_class=&quot;banjo&quot;, minimal_cost=0.9, noise_clip=(-2,2)) . #0 predicted likelihood for banjo is 0.007987% #15 predicted likelihood for banjo is 66.04% break@ #18 predicted likelihood for banjo is 93.77% . Let&#39;s come back with the frog. We can try to blur the adversarial image in order to cancel the noise. But it won&#39;t correctly classify our image . from scipy import ndimage from scipy import misc blurred_adversarial_frog = ndimage.gaussian_filter(rebuild_image(adversarial_frog[0]), sigma=1) predictions = model.predict(process_image(blurred_adversarial_frog)) get_predictions(predictions) . [(&#39;n03388043&#39;, &#39;fountain&#39;, 0.05666038), (&#39;n01773549&#39;, &#39;barn_spider&#39;, 0.051836845), (&#39;n04548362&#39;, &#39;wallet&#39;, 0.03691612)] . Since the noise is small, a better strategy would be to lower the bit-depth of the input image. .",
            "url": "https://data-soup.github.io/blog/2018/10/16/Adversarial-Resnet50.html",
            "relUrl": "/2018/10/16/Adversarial-Resnet50.html",
            "date": " • Oct 16, 2018"
        }
        
    
  
    
        ,"post5": {
            "title": "Machine Learning's Security Layer, an Overview",
            "content": "This is a shallow overview of the security of machine learning systems. Within a few scrolls we’ll go through: . ️Adversarial Example | Model Theft | Dataset Poisoning | Dataset Protection | . ️Adversarial Examples . The adversarial examples (AE) topic is fascinating and an active area of research. It raises fundamental questions related to the limits and the security of our current gradient-based classifier architectures. AE are cleverly crafted data designed to be misclassified by a targeted model. They are “designed to cause the model to make a mistake” (OpenAI, Attacking Machine Learning with Adversarial Examples). The image on the right is an adversarial example. . . The difference between the left and the rightmost dog is probably unperceptible. This can be due to our eyes limitations (or the bit depth of your monitor). And yet they are crucial to various models. The last image is indeed considered as a plane by a ResNet50 initialized with default training weight in Keras, and one AE will probably work on another architecture. The only difference are small pixels values, amplified in the second picture. . We can notice that ResNet50 was pretty confident that the dog on the left picture is a golden_retriever (~80%) and the crafted image is a plane with a higher confidence (~99%). So a model can be tricked into making a mistake with the confidence score we desire, we in general just need to train it long enough. What are the impacts of misclassifying with an arbitrary confidence score? . Recommendation systems are also studied for adversarial recommendation, influencing a recommendation system through indistinguishable fake users. . Safety . In most known models, any image can be crafted into another class with an arbitrary confidence score. So our dog can be misclassified as anything we wish with any arbitrary accuracy. It has been shown that it works in the physical world too, for instance, if we print them. A famous example is tricking a car’s sensor to see a speed limit instead of a STOP sign. The output of a model can be manipulated into making to some extent, a desired decision or at generating unhandled behavior by the application that relies on it. . . By the end of 2017 some showed that modifying one pixel can be enough in some cases. If you want to know more about this you can read the paper One pixel attack for fooling deep neural networks, enjoy a high-level presentation by the One minute paper channel or check this Keras implementation. . Adversarial examples are simple attack and don’t require much computation. On relatively small images a good GPU can craft an AE in less than a minute. This is a real security issue and that is probably why we can read those line at the end of some related subject papers: . Research was also supported in part by the Army Research Laboratory, under Cooperative Agreement Number W911NF-13-2-0045 (ARL Cyber Security CRA), and the Army Research Office under grant W911NF-13-1-0421. . Different threats level and techniques . We know that adversarial examples play with the decision boundaries of a classifier. We can, for instance, add random pixels on an image and change the classification or wisely choose those added pixels and choose the classification. Depending on the threat objective we denote: . Confidence reduction increases the ambiguity between classes by reducing the model’s confidence for a given image. | Misclassification changes the output class to another class than the original one. | Targeted misclassification forces the output of a specific input to be a specific target class. | . Depending on the opponent’s knowledge, there are three ways of crafting adversarial examples. Each with their own assumed prior knowledge of the target. Knowing: . the model as a whole including its weights (gradient-base), | only the score of each class (score-based), | only the prediction (transfer-based). | . A simplified copy of a diagram by Papernot. et al in The Limitations of Deep Learning in Adversarial Settings (page 3): . . One example of gradient-base attack consists in computing the loss’ gradient function an image. Following by a tiny step in the opposite gradient’s direction. In order to keep valid RGB values, the image might be clipped between 0 and 255 and the value of the noise between 0 and a small value, M. This value M determine the maximum difference between the original image and the adversarial one, so M should be smaller than a human’s color sensibility (through a monitor). M smaller than 5 should be fine. The previous technique is called the iterative least-likely class method. Other types of gradient techniques exist like a fast gradient sign method. You can read this paper (part 2, page 3). We can note that they all require a complete knowledge of the model and its weights. . Score-based attacks rely only on the predicted model’s score to estimate the gradient and then apply the previous technique. Transfer-based attacks rely exclusively on the output label. This is a more realistic scenario compared to score-based and gradient-based. You can find an example of a transfer-based attack in the section Model Theft. . Defence . Here we won’t go much in depth I encourage you to search the keywords that attract you, it deserves a blog post on its own. We can see two big categories of defences: . Reactive: where the objective is an adversarial example prior being called on by our model for an inference. | Proactive: where the objective is to make the models more resilient to this kind of attack. Black Box Attacks by Nicolas Papernot et al. | . Example of reactive defenses: . MagNet a ‘two networks’ model composed of an auto-encoder capable of reforming before being fed to a classifier. Several auto-encoder are needed here so it’s resource expensive. | . Example of proactive defenses: . Random depthwise signed convolutional neural networks | Label smoothing (2016) | Mixup (2017) | Adversarial training, re-training the neural network with a subset of adversarial examples | Logit pairing this one is very new (2018) and “achieves the state of the art defense for white box and black box attacks on ImageNet” | . Model Theft . Trying to rebuild someone’s else model or retrieve data that were used to train the model. The dataset and or the model might be confidential for their sensitive or commercial value. . The tension between model confidentiality and public access motivates our investigation of model extraction attacks. (Source) . We’ll summarize briefly the Black Box Attacks by Nicolas Papernot et al. If you want to dig this subject you might enjoy reading it. The main idea described here is to create a local substitute neural network trained with a substitute dataset crafted by the adversary. Then, using gradient-based techniques adversarial examples can be generated. . &lt;img src=”/blog/images/ml-sec/flowchart-black-box-attack.png” “Figure 3 - arxiv.org/abs/1602.02697”&gt; . There’s no need for a labeled dataset, which can be expensive to produce. The substitute dataset is labeled using the remote DNN’s output. Then the local dataset is locally augmented through a technique called Jacobian-based Dataset Augmentation. Here is a pseudo code describing the Jacobian data augmentation (full code available on github). . def jacobian_augmentation(dataset): &quot;&quot;&quot; - get_label: API call on the remote oracle - alpha: step size - jacobian: returns jacobian matrix of the substitute model &quot;&quot;&quot; jacobian_dataset = [] for sample in dataset: label = get_label(sample) jacobian_sample = sample + alpha*sign(jacobian(substitute_model, label)) jacobian_dataset.append(jacobian_sample) return jacobian_dataset . Basically, each example is augmented by adding a small variation in direction of the gradient. . They emphasize that: . […] this technique is not designed to maximize the substitute DNN’s accuracy but rather ensure that it approximates the oracle’s decision boundaries with few label queries. . The choice of architecture isn’t very important since we can assume some details beforehand. There is a high chance that a CNN was used for an image classification task. It is also possible to train simultaneously several architectures. . An implementation of a similar attack is available on Github. . Dataset Poisoning . Dataset poisoning attacks aim at manipulating model’s behavior at test time. . Poisoning 3% of a training set managed to drop the test accuracy by 11% (Certified Defenses for Data Poisoning Attacks by Steinhardt at al. (2017)). . Label flipping attack the objective is to maximize the loss function if a subset of the training example’s label is flipped, this is basically done by gradient ascent: . . An attacker first chooses a target instance from the test set; a successful poisoning attack causes this target example to be misclassified during test time. Next, the attacker samples a base instance from the base class, and makes imperceptible changes to it to craft a poison instance; this poison is injected into the training data with the intent of fooling the model into labeling the target instance with the base label at test time. Finally, the model is trained on the poisoned dataset (clean dataset + poison instances). If during test time the model mistakes the target instance as being in the base class, then the poisoning attack is considered successful Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks . Dataset Protection . Fully homomorphic encryption . . Fully homomorphic encryption is an encryption scheme that preserves the operation on data through encryption and decryption function. If the scheme is preserved over the addition, encrypting a sum or summing the encrypted members will give the same result. This means that you can encrypt your data locally and send it to a server, let it do a job using only the supported operators and return you the encrypted result. You don’t need to trust the server since it won’t understand what it is manipulating. . Let ENC and DEC the encryption and decryption function respectively: . ENC(X1 + X2) = ENC(X1) + ENC(X2) (homomorphism) Since X1 + X2 = DEC(ENC(X1+ X2)) We have X1 + X2 = DEC(ENC(X1) + ENC(X2)) . If you would need to follow one person in this field, it would be Craig Gentry. He found the first FHE scheme in 2009. . Much of Craig’s recent work, including FHE and cryptographic multilinear maps, generally falls into the area of “lattice-based cryptography”. Unlike commonly-used cryptosystems like RSA and elliptic-curve cryptography, lattice-based cryptosystems cannot feasibly (as far as we know) be broken by quantum computers. (IBM) . The most important part here is that if one day this encryption schemes exists we can (almost) not care about the privacy of our data we’re sending on a remote machine. If this machine is malicious it can just give you wrong results but can’t exploit your data… Unless… If we’re talking about an FH encrypted machine learning model trying to predict something, nothing guarantees you that the model is empty at first and your opponent can still do inferences on the young model (by observing boundaries decisions and such). You should check out CryptoDL. . Dataset theft . It is also possible to recover the data used at training by simply looking at the model’s output, Membership Inference Attacks Against Machine Learning Models: . given a data record and black-box access to a model, determine if the record was in the model’s training dataset. To perform membership inference against a target model, we make adversarial use of machine learning and train our own inference model to recognize differences in the target model’s predictions on the inputs that it trained on versus the inputs that it did not train on. . An implementation can be found here. .",
            "url": "https://data-soup.github.io/blog/2018/10/02/machine-learning-security.html",
            "relUrl": "/2018/10/02/machine-learning-security.html",
            "date": " • Oct 2, 2018"
        }
        
    
  
    
        ,"post6": {
            "title": "Parkinson's disease telemonitoring. A regression with Keras.",
            "content": "Suitability of Dysphonia Measurements for Telemonitoring of Parkinson&#39;s Disease : . Parkinson’s disease affects over one million people in North America alone. Moreover, an aging population means this number is expected to rise as studies suggest rapidly increasing prevalence rates after the age of 60. . . Research has shown that approximately 90% of people with Parkinson exhibit some form of vocal impairment. Vocal impairment may also be one of the earliest indicators for the onset of the illness, and the measurement of voice is noninvasive and simple to administer . import numpy as np import pandas as pd import matplotlib.pyplot as plt data_root = &#39;../input/&#39; df = pd.read_csv(data_root+&#39;parkinsons_updrs.data&#39;) print(df.shape) print(df.columns) df.head(5) . (5875, 22) Index([&#39;subject#&#39;, &#39;age&#39;, &#39;sex&#39;, &#39;test_time&#39;, &#39;motor_UPDRS&#39;, &#39;total_UPDRS&#39;, &#39;Jitter(%)&#39;, &#39;Jitter(Abs)&#39;, &#39;Jitter:RAP&#39;, &#39;Jitter:PPQ5&#39;, &#39;Jitter:DDP&#39;, &#39;Shimmer&#39;, &#39;Shimmer(dB)&#39;, &#39;Shimmer:APQ3&#39;, &#39;Shimmer:APQ5&#39;, &#39;Shimmer:APQ11&#39;, &#39;Shimmer:DDA&#39;, &#39;NHR&#39;, &#39;HNR&#39;, &#39;RPDE&#39;, &#39;DFA&#39;, &#39;PPE&#39;], dtype=&#39;object&#39;) . subject# age sex test_time motor_UPDRS total_UPDRS Jitter(%) Jitter(Abs) Jitter:RAP Jitter:PPQ5 ... Shimmer(dB) Shimmer:APQ3 Shimmer:APQ5 Shimmer:APQ11 Shimmer:DDA NHR HNR RPDE DFA PPE . 0 1 | 72 | 0 | 5.6431 | 28.199 | 34.398 | 0.00662 | 0.000034 | 0.00401 | 0.00317 | ... | 0.230 | 0.01438 | 0.01309 | 0.01662 | 0.04314 | 0.014290 | 21.640 | 0.41888 | 0.54842 | 0.16006 | . 1 1 | 72 | 0 | 12.6660 | 28.447 | 34.894 | 0.00300 | 0.000017 | 0.00132 | 0.00150 | ... | 0.179 | 0.00994 | 0.01072 | 0.01689 | 0.02982 | 0.011112 | 27.183 | 0.43493 | 0.56477 | 0.10810 | . 2 1 | 72 | 0 | 19.6810 | 28.695 | 35.389 | 0.00481 | 0.000025 | 0.00205 | 0.00208 | ... | 0.181 | 0.00734 | 0.00844 | 0.01458 | 0.02202 | 0.020220 | 23.047 | 0.46222 | 0.54405 | 0.21014 | . 3 1 | 72 | 0 | 25.6470 | 28.905 | 35.810 | 0.00528 | 0.000027 | 0.00191 | 0.00264 | ... | 0.327 | 0.01106 | 0.01265 | 0.01963 | 0.03317 | 0.027837 | 24.445 | 0.48730 | 0.57794 | 0.33277 | . 4 1 | 72 | 0 | 33.6420 | 29.187 | 36.375 | 0.00335 | 0.000020 | 0.00093 | 0.00130 | ... | 0.176 | 0.00679 | 0.00929 | 0.01819 | 0.02036 | 0.011625 | 26.126 | 0.47188 | 0.56122 | 0.19361 | . 5 rows × 22 columns . fig, ax = plt.subplots(1,1) df[&quot;motor_UPDRS&quot;].plot(kind=&quot;density&quot;) df[&quot;total_UPDRS&quot;].plot(kind=&quot;density&quot;) fig.show() . /opt/conda/lib/python3.6/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure &#34;matplotlib is currently using a non-GUI backend, &#34; . male = len(df[df[&#39;sex&#39;] == 0]) female = len(df[df[&#39;sex&#39;] == 1]) print(&quot;There is {0} males and {1} females.&quot;.format(male, female)) . There is 4008 males and 1867 females. . def corr_sub_plot(ax, df, title=&quot;&quot;): corr = df.corr() avg_corr = np.absolute(corr.values[np.triu_indices_from(corr.values,1)]).mean() ax.set_title(title+&quot; (abs(average)={0:.4})&quot;.format(avg_corr)) ax.set_xticks(np.arange(len(df.columns))) ax.set_yticks(np.arange(len(df.columns))) ax.set_yticklabels(df.columns) ax.set_xticklabels(df.columns) return ax.imshow(corr, interpolation=&quot;nearest&quot;, cmap=&#39;cool&#39;, vmin=-1, vmax=1) fig, ax = plt.subplots() cax = corr_sub_plot(ax, df.iloc[:,17:], title=&quot;Correlation plot &quot;) fig.colorbar(cax); . High negative correlaton between HNR and the other selected variables. . According to this paper: HNR = 10 * log_10(Energy_in_periodic_part/Energy_in_noise) . Voice quality can be dertermined using such a measure (source): . a healthy speaker can produce a sustained [a] or [i] with a harmonicity of around 20 dB, and an [u] at around 40 dB; the difference comes from the high frequencies in [a] and [i], versus low frequencies in [u], resulting in a much higher sensitivity of HNR to jitter in [a] and [i] than in [u]. Hoarse speakers will have an [a] with a harmonicity much lower than 20 dB. We know of a pathological case where a speaker had an HNR of 40 dB for [i], because his voice let down above 2000 Hz. . Since usually men and women&#39;s voices lies in different fundamental frequencies we can probably find something. Those scatter plots may help us: . from itertools import combinations def scatter_patient(df, subject_list, columns, patient_filter, scatter_alpha=0.3): fig, ax = plt.subplots(figsize=(30,22)) f = [comb for comb in combinations(range(len(columns)), 2)] for _, fp, _ in patient_filter: fp = fp &amp; subject_list for i in range(len(f)): plt.subplot(5,5,i + 1) column_1 = columns[f[i][0]] column_2 = columns[f[i][1]] for name, fp, color in patient_filter: plt.scatter(df[fp][column_1], df[fp][column_2], alpha=scatter_alpha, marker=&#39;.&#39;, color=color, s=5, label=name) plt.xlabel(column_1) plt.ylabel(column_2) if(i == 0 or i == len(f)): plt.legend(markerscale=5, framealpha=1) sex_filter_patient = [(&#39;Men&#39;, df[&#39;sex&#39;] == 0, &#39;red&#39;), (&#39;Women&#39;, df[&#39;sex&#39;] == 1, &#39;black&#39;)] scatter_patient(df, df[&#39;subject#&#39;] == df[&#39;subject#&#39;], [&#39;NHR&#39;, &#39;HNR&#39;, &#39;PPE&#39;, &#39;DFA&#39;, &#39;RPDE&#39;], sex_filter_patient) . In the end apparently not much difference. Women, even if represented twice less than men, tends to have more spreaded values. . Using the same representation we can have a look at age. . pd.DataFrame(df.age).plot(kind=&quot;density&quot;); . low_margin = 66 less = df[&#39;age&#39;] &lt;= low_margin more = df[&#39;age&#39;] &gt; low_margin age_filter_patient = [(&#39;Age&lt;{}&#39;.format(low_margin), less, &#39;green&#39;), (&#39;{}&gt;Age&#39;.format(low_margin), more, &#39;black&#39;)] scatter_patient(df, True, [&#39;NHR&#39;, &#39;HNR&#39;, &#39;PPE&#39;, &#39;DFA&#39;, &#39;RPDE&#39;], age_filter_patient, scatter_alpha=0.3) . Pipelining and modeling the regression. . from sklearn.pipeline import Pipeline, make_pipeline from sklearn.preprocessing import StandardScaler from sklearn.base import BaseEstimator, TransformerMixin from sklearn.decomposition import PCA numerical = [&#39;Jitter(%)&#39;, &#39;Jitter(Abs)&#39;,&#39;Jitter:RAP&#39;,&#39;Jitter:PPQ5&#39;,&#39;Jitter:DDP&#39;, &#39;Shimmer&#39;,&#39;Shimmer(dB)&#39;,&#39;Shimmer:APQ3&#39;,&#39;Shimmer:APQ5&#39;,&#39;Shimmer:APQ11&#39;,&#39;Shimmer:DDA&#39;, &#39;NHR&#39;, &#39;HNR&#39;, &#39;RPDE&#39;, &#39;DFA&#39;, &#39;PPE&#39;, &#39;age&#39;, &#39;sex&#39;, &#39;test_time&#39;] features_pipe = make_pipeline(StandardScaler(), PCA(n_components=0.95)) targets_pipe = make_pipeline(StandardScaler()) X = features_pipe.fit_transform(df[numerical]) targets = df[[&#39;motor_UPDRS&#39;, &#39;total_UPDRS&#39;]] y = targets_pipe.fit_transform(targets) input_width = X.shape[1] print(input_width) . 8 . from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = df[&#39;subject#&#39;], train_size=0.9, random_state=4422) X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=4422) . /opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified. FutureWarning) . import keras from keras.callbacks import EarlyStopping from IPython.display import clear_output from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes from mpl_toolkits.axes_grid1.inset_locator import mark_inset earlystop = EarlyStopping(monitor=&#39;val_loss&#39;, min_delta=0.005, patience=200, verbose=1, mode=&#39;min&#39;) # forked from: gist.github.com/stared/dfb4dfaf6d9a8501cd1cc8b8cb806d2e class PlotLosses(keras.callbacks.Callback): def __init__(self, skip=5, refresh_rate=5, figsize=(17,10), zoom_delta=7): self.skip = skip self.refresh_rate= refresh_rate self.figsize=figsize self.fig = plt.figure() self.zoom_delta = zoom_delta def on_train_begin(self, logs={}): self.i = 0 self.x = [] self.losses = [] self.val_losses = [] self.logs = [] def on_epoch_end(self, epoch, logs={}): last_loss = logs.get(&#39;loss&#39;) last_val_loss = logs.get(&#39;val_loss&#39;) self.x.append(self.i) self.losses.append(last_loss) self.val_losses.append(last_val_loss) self.i += 1 if(self.i % self.refresh_rate == 0 and self.i &gt; self.skip): clear_output(wait=True) fig = plt.figure(figsize=self.figsize) ax = fig.add_subplot(2, 1, 1) ax.plot(self.x[self.skip:], self.losses[self.skip:], label=&quot;loss&quot;); ax.plot(self.x[self.skip:], self.val_losses[self.skip:], label=&quot;val_loss&quot;); plt.title(&quot;{0:.4} loss &amp; {1:.4} validation loss (epoch={2})&quot;.format(last_loss, last_val_loss, self.i)) plt.legend() if(self.i &gt; 100): zoom = min(int(self.i/300) + 1, 4) axins = zoomed_inset_axes(ax, zoom, loc=7) last_epochs = slice(self.i-self.zoom_delta-1,self.i-1) min_y = min(min(self.losses[last_epochs]), min(self.val_losses[last_epochs])) max_y = max(max(self.losses[last_epochs]), max(self.val_losses[last_epochs])) if(max_y - min_y &lt; 0.2): max_y += 0.04/zoom min_y -= 0.04/zoom axins.plot(self.x[self.skip:], self.losses[self.skip:]) axins.plot(self.x[self.skip:], self.val_losses[self.skip:]) axins.set_xlim(last_epochs.start, last_epochs.stop) axins.set_ylim(min_y, max_y) mark_inset(ax, axins, loc1=3, loc2=4, fc=&quot;none&quot;, ec=&quot;0.5&quot;) plt.show() . /opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters Using TensorFlow backend. . from keras.models import Sequential from keras.layers import Dense, Activation, Dropout, BatchNormalization plot_losses = PlotLosses() def make_fully_connected_regressor(neuron_per_layers, input_shape): model = Sequential([ Dense(neuron_per_layers, input_shape=input_shape, kernel_initializer=&#39;he_uniform&#39;, activation=&#39;relu&#39;), BatchNormalization(), Dropout(0.4), Dense(neuron_per_layers, kernel_initializer=&#39;he_uniform&#39;, activation=&#39;relu&#39;), BatchNormalization(), Dropout(0.2), Dense(neuron_per_layers, kernel_initializer=&#39;he_uniform&#39;, activation=&#39;relu&#39;), BatchNormalization(), Dense(2, kernel_initializer=&#39;he_uniform&#39;, activation=&#39;linear&#39;), ]) model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;) return model . &lt;matplotlib.figure.Figure at 0x7f510a6b0c50&gt; . model = make_fully_connected_regressor(neuron_per_layers=105, input_shape=(input_width,)) load_model = False if(not load_model): model.fit(X_train, y_train, epochs=2000, batch_size=256, verbose=0, validation_data=(X_val, y_val), callbacks=[earlystop, plot_losses]) model.save(&#39;model_1.h5&#39;) else: from keras.models import load_model as load_model_ model = load_model_(&#39;model_1.h5&#39;) . Epoch 01561: early stopping . Let&#39;s compute the mean squarred errors on the inverse transformed output on the test set. . from sklearn.metrics import mean_squared_error test_predictions = model.predict(X_test) inversed_test_labels = targets_pipe.inverse_transform(y_test) inversed_predictions = targets_pipe.inverse_transform(test_predictions) motor_UPDRS_se = mean_squared_error(inversed_test_labels[:,0], inversed_predictions[:,0]) total_UPDRS_se = mean_squared_error(inversed_test_labels[:,1], inversed_predictions[:,1]) motor_UPDRS_se, total_UPDRS_se . (5.376922629983537, 8.886180184526083) . Let&#39;s try to blindly search for new features. . transforms = [np.exp, np.log, np.tanh, np.power, np.sqrt] for e in numerical: ref_motor = abs(np.corrcoef(df[e], df[&#39;motor_UPDRS&#39;])).mean() ref_total = abs(np.corrcoef(df[e], df[&#39;total_UPDRS&#39;])).mean() print(&quot;Current column={0}&quot;.format(e)) for t in transforms: transformed = 0 if t is np.power: transformed = t(df[e],2) else: transformed = t(df[e]) motor = abs(np.corrcoef(transformed, df[&#39;motor_UPDRS&#39;])).mean() total = abs(np.corrcoef(transformed, df[&#39;total_UPDRS&#39;])).mean() if(motor &gt;= ref_motor + 0.01): diff = motor - ref_motor print(&quot;transformer={0} enhance correlation for motor_UPDRS (+{1:.4} +{2:.4})&quot;.format(t, motor - ref_motor, ((ref_motor+diff)/ref_motor - 1)*100)) if(total &gt;= ref_total + 0.01): diff = total - ref_total print(&quot;transformer={0} enhance correlation for total_UPDRS (+{1:.4} +{2:.4}%)&quot;.format(t, total - ref_total, ((ref_total+diff)/ref_total - 1)*100)) . Current column=Jitter(%) transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for motor_UPDRS (+0.02262 +4.17) transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for total_UPDRS (+0.02912 +5.421%) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for motor_UPDRS (+0.01369 +2.524) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for total_UPDRS (+0.0159 +2.959%) Current column=Jitter(Abs) transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for motor_UPDRS (+0.01716 +3.265) transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for total_UPDRS (+0.03118 +5.845%) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for total_UPDRS (+0.01509 +2.828%) Current column=Jitter:RAP transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for motor_UPDRS (+0.01929 +3.596) transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for total_UPDRS (+0.0245 +4.606%) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for motor_UPDRS (+0.01199 +2.236) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for total_UPDRS (+0.01369 +2.573%) Current column=Jitter:PPQ5 transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for motor_UPDRS (+0.02529 +4.7) transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for total_UPDRS (+0.03177 +5.976%) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for motor_UPDRS (+0.01516 +2.818) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for total_UPDRS (+0.017 +3.198%) Current column=Jitter:DDP transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for motor_UPDRS (+0.0193 +3.599) transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for total_UPDRS (+0.02452 +4.608%) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for motor_UPDRS (+0.012 +2.237) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for total_UPDRS (+0.01369 +2.574%) Current column=Shimmer transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for motor_UPDRS (+0.01348 +2.446) transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for total_UPDRS (+0.02078 +3.805%) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for total_UPDRS (+0.01227 +2.247%) Current column=Shimmer(dB) transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for motor_UPDRS (+0.01288 +2.32) transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for total_UPDRS (+0.01977 +3.598%) transformer=&lt;ufunc &#39;tanh&#39;&gt; enhance correlation for total_UPDRS (+0.01118 +2.036%) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for total_UPDRS (+0.01179 +2.145%) Current column=Shimmer:APQ3 transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for total_UPDRS (+0.01671 +3.095%) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for total_UPDRS (+0.01051 +1.947%) Current column=Shimmer:APQ5 transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for motor_UPDRS (+0.0114 +2.088) transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for total_UPDRS (+0.01967 +3.631%) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for total_UPDRS (+0.01217 +2.247%) Current column=Shimmer:APQ11 transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for motor_UPDRS (+0.01259 +2.216) transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for total_UPDRS (+0.02116 +3.775%) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for total_UPDRS (+0.01311 +2.339%) Current column=Shimmer:DDA transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for total_UPDRS (+0.01671 +3.096%) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for total_UPDRS (+0.01051 +1.947%) Current column=NHR transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for motor_UPDRS (+0.03612 +6.72) transformer=&lt;ufunc &#39;log&#39;&gt; enhance correlation for total_UPDRS (+0.04456 +8.401%) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for motor_UPDRS (+0.01962 +3.65) transformer=&lt;ufunc &#39;sqrt&#39;&gt; enhance correlation for total_UPDRS (+0.02204 +4.155%) Current column=HNR transformer=&lt;ufunc &#39;power&#39;&gt; enhance correlation for total_UPDRS (+0.0128 +2.204%) Current column=RPDE Current column=DFA Current column=PPE Current column=age Current column=sex Current column=test_time . /opt/conda/lib/python3.6/site-packages/numpy/lib/function_base.py:3183: RuntimeWarning: invalid value encountered in true_divide c /= stddev[:, None] /opt/conda/lib/python3.6/site-packages/numpy/lib/function_base.py:3184: RuntimeWarning: invalid value encountered in true_divide c /= stddev[None, :] /opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log del sys.path[0] /opt/conda/lib/python3.6/site-packages/numpy/lib/function_base.py:3103: RuntimeWarning: invalid value encountered in subtract X -= avg[:, None] /opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in log del sys.path[0] /opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in sqrt del sys.path[0] . to_log = [&#39;Jitter(%)&#39;, &#39;Jitter(Abs)&#39;,&#39;Jitter:RAP&#39;,&#39;Jitter:PPQ5&#39;,&#39;Jitter:DDP&#39;,&#39;Shimmer&#39;,&#39;Shimmer(dB)&#39;,&#39;Shimmer:APQ3&#39;,&#39;Shimmer:APQ5&#39;,&#39;Shimmer:APQ11&#39;,&#39;Shimmer:DDA&#39;,&#39;NHR&#39;] for feature in to_log: df[feature+&#39;_log&#39;] = np.log(df[feature]) df[&#39;HNR_sq&#39;] = np.power(df[&#39;HNR&#39;],2) . numerical_v2 = [&#39;Jitter(%)_log&#39;, &#39;Jitter(Abs)_log&#39;,&#39;Jitter:RAP_log&#39;,&#39;Jitter:PPQ5_log&#39;,&#39;Jitter:DDP_log&#39;, &#39;Shimmer_log&#39;,&#39;Shimmer(dB)_log&#39;,&#39;Shimmer:APQ3_log&#39;,&#39;Shimmer:APQ5_log&#39;,&#39;Shimmer:APQ11_log&#39;,&#39;Shimmer:DDA_log&#39;, &#39;NHR_log&#39;, &#39;HNR_sq&#39;] + numerical features_pipe_v2 = make_pipeline(StandardScaler(), PCA(n_components=0.96)) targets_pipe_v2 = make_pipeline(StandardScaler()) X2 = features_pipe_v2.fit_transform(df[numerical_v2]) y2 = targets_pipe_v2.fit_transform(targets) X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, train_size=0.9, random_state=4422) X2_train, X2_val, y2_train, y2_val = train_test_split(X2_train, y2_train, test_size=0.2, random_state=4422) input_width2 = X2.shape[1] print(input_width2) . File &#34;&lt;ipython-input-16-b43a255cebd0&gt;&#34;, line 11 X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, train_size=0.9, , random_state=4422) ^ SyntaxError: invalid syntax . augmented_model = make_fully_connected_regressor(neuron_per_layers=105, input_shape=(input_width2,)) augmented_model.fit(X2_train, y2_train, epochs=2000, batch_size=256, verbose=0, validation_data=(X2_val, y2_val), callbacks=[earlystop, plot_losses]) . test_predictions = augmented_model.predict(X2_test) inversed_test_labels = targets_pipe_v2.inverse_transform(y2_test) inversed_predictions = targets_pipe_v2.inverse_transform(test_predictions) motor_UPDRS_se = mean_squared_error(inversed_test_labels[:,0], inversed_predictions[:,0]) total_UPDRS_se = mean_squared_error(inversed_test_labels[:,1], inversed_predictions[:,1]) motor_UPDRS_se, total_UPDRS_se .",
            "url": "https://data-soup.github.io/blog/2018/04/20/Parkinson-Telemonitoring-Regression-with-Keras.html",
            "relUrl": "/2018/04/20/Parkinson-Telemonitoring-Regression-with-Keras.html",
            "date": " • Apr 20, 2018"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "This blog aims at summarizing what I find interesting in my ML learning path. You can contact me through the comment section or by the social links in the footer. . Powered by fastpages. .",
          "url": "https://data-soup.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://data-soup.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}