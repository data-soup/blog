{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-08-03-managing-ml-experiments-with-one-file.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLf-XD3LwpbQ",
        "colab_type": "text"
      },
      "source": [
        "# Managing  experiments with one file\n",
        "\n",
        "> Presenting an experiment manager contained in one file for `tf.keras`\n",
        "\n",
        "- toc: true\n",
        "- badges: true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oATNliK7SHQ",
        "colab_type": "text"
      },
      "source": [
        "Let's say you want to test different hyperparameters on a given model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmJKp6lQtgIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        ")\n",
        "\n",
        "def get_model(params):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(params['conv_0'], kernel_size=params['kernel_0'],\n",
        "                  activation='relu',\n",
        "                  input_shape=params['input_shape']))\n",
        "  model.add(Conv2D(params['conv_1'], params['kernel_1'], activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=params['pool_size']))\n",
        "  model.add(Dropout(params['dropout_0']))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(params['dense'], activation='relu'))\n",
        "  model.add(Dropout(params['dropout_1']))\n",
        "  model.add(Dense(params['num_classes'], activation='softmax'))\n",
        "  return model\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mceD6apzxCgA",
        "colab_type": "text"
      },
      "source": [
        "We then feed the `get_model` function with something like this:\n",
        "\n",
        "```\n",
        "'model': {\n",
        "    'input_shape': (28, 28, 1),\n",
        "    'conv_0': 32,\n",
        "    'conv_1': 64,\n",
        "    'kernel_0': (3,3),\n",
        "    'kernel_1': (3,3),\n",
        "    'pool_size': (2,2),\n",
        "    'dropout_0': 0.25,\n",
        "    'dense': 128,\n",
        "    'dropout_1': 0.5,\n",
        "    'num_classes': 10\n",
        "}\n",
        "```\n",
        "\n",
        "The [experiment manager](https://github.com/maxpv/experiment_manager), is here to automatically keep a tidy model checkpoints, performance files for your hyperparameter search. It's doing so by maintaining a consistent folder hierarchy based on the hash of your hyperparameters.\n",
        "\n",
        "Let's see a real example, by defining our hyperparameters. We choose here (but you can do what you want) to separate them into two sections: \n",
        "- `training` which contains the parameters such as the batch size, the selected optimizer, ...\n",
        "- `model`  which contains the parameters that actually build your model\n",
        "\n",
        "Note that you can create as many section as you want and use as much nested dictionary as necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8zFisKv1Zjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "    'debug': False,\n",
        "    'training': {\n",
        "      'batch_size': 128,\n",
        "      'epochs': 3  \n",
        "    },\n",
        "    'model': {\n",
        "      'input_shape': (28, 28, 1),\n",
        "      'conv_0': 32,\n",
        "      'conv_1': 64,\n",
        "      'kernel_0': (3,3),\n",
        "      'kernel_1': (3,3),\n",
        "      'pool_size': (2,2),\n",
        "      'dropout_0': 0.25,\n",
        "      'dense': 128,\n",
        "      'dropout_1': 0.5,\n",
        "      'num_classes': 10\n",
        "    },\n",
        "    'comment': 'simple model from keras documentation',\n",
        "    'author': 'data-soup'\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzKpG8X7ubT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "30b60a97-b725-4267-a389-5350505ef5f6"
      },
      "source": [
        "#collapse\n",
        "!sudo apt-get install tree # usefull later to display the directories\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = params['model']['input_shape'][:2]\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 40.7 kB of archives.\n",
            "After this operation, 105 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tree amd64 1.7.0-5 [40.7 kB]\n",
            "Fetched 40.7 kB in 0s (112 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 144579 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a5OKszxvKTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "36c723e8-325a-439c-949f-fadd0e0ca86a"
      },
      "source": [
        "#collapse\n",
        "# Here lives the code for the experiement manager\n",
        "!git clone https://github.com/maxpv/experiment_manager"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'experiment_manager'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 24 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (24/24), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAK9mfz221BJ",
        "colab_type": "text"
      },
      "source": [
        "We can now prepare the `ExperimentManager` for a first test run.\n",
        "\n",
        "- `exp_base_dir` is the name of your experiment, can be the version of `get_model` or anything else\n",
        "- `monitored_param_keys` will manage your experiments based on those keys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl29rIp2uvs0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ccd8a744-11ce-44f3-d5f3-5aa4c55cbd3a"
      },
      "source": [
        "from experiment_manager.experiment_manager import ExperimentManager\n",
        "expm = ExperimentManager(exp_base_dir='experiments', \n",
        "      monitored_param_keys=['training', 'model'])\n",
        "callbacks = expm.prepare(params)\n",
        "\n",
        "model = get_model(params['model'])\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train[:5000], y_train[:5000],\n",
        "          **params['training'],\n",
        "          verbose=1,\n",
        "          callbacks = callbacks, \n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now everything is happening in /content/experiments/exp--72399506-44712951/run--20-09-04--16-11\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 17s 416ms/step - loss: 0.8887 - accuracy: 0.7264 - val_loss: 0.3282 - val_accuracy: 0.9063\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3505 - accuracy: 0.8956 - val_loss: 0.1944 - val_accuracy: 0.9412\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.2214 - accuracy: 0.9364 - val_loss: 0.1378 - val_accuracy: 0.9564\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9925c67780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzTWk966yOKX",
        "colab_type": "text"
      },
      "source": [
        "The training above generated:\n",
        "\n",
        "1. a tree structure for each experiment under a specific identifier and the current date\n",
        "2. callbacks for tf.keras to ensure that training logs and model checkpoints are written in the same directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq3bJL_4v45T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "24658fa3-7c70-4834-ad7c-e3fee1979f0f"
      },
      "source": [
        "!tree experiments"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "experiments\n",
            "└── exp--72399506-44712951\n",
            "    └── run--20-09-04--16-11\n",
            "        ├── hyperparameters.json\n",
            "        ├── models\n",
            "        │   ├── model.01-0.3282.hdf5\n",
            "        │   ├── model.02-0.1944.hdf5\n",
            "        │   └── model.03-0.1378.hdf5\n",
            "        ├── performances.json\n",
            "        └── training-logs.csv\n",
            "\n",
            "3 directories, 6 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTBGmewPzPGN",
        "colab_type": "text"
      },
      "source": [
        "Now let's launch another run using the same parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofril5dYzDTO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a24a6f18-c8db-4b8c-db53-5610cbc56f6d"
      },
      "source": [
        "#collapse\n",
        "callbacks = expm.prepare(params)\n",
        "\n",
        "model = get_model(params['model'])\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train[:5000], y_train[:5000],\n",
        "          **params['training'],\n",
        "          verbose=1,\n",
        "          callbacks = callbacks,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now everything is happening in /content/experiments/exp--72399506-44712951/run--20-09-04--16-12\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 17s 417ms/step - loss: 0.8838 - accuracy: 0.7252 - val_loss: 0.3311 - val_accuracy: 0.8998\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 17s 413ms/step - loss: 0.3274 - accuracy: 0.9008 - val_loss: 0.1808 - val_accuracy: 0.9466\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 17s 414ms/step - loss: 0.1997 - accuracy: 0.9396 - val_loss: 0.1402 - val_accuracy: 0.9570\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9922ce9fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IinGmzezHqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f129f081-4565-4ae9-d905-107c187422b7"
      },
      "source": [
        "!tree experiments -d"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "experiments\n",
            "└── exp--72399506-44712951\n",
            "    ├── run--20-09-04--16-11\n",
            "    │   └── models\n",
            "    └── run--20-09-04--16-12\n",
            "        └── models\n",
            "\n",
            "5 directories\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-ps_FRGzUTl",
        "colab_type": "text"
      },
      "source": [
        "Let's see what happens if we change the model parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43Q_VGCNzD9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "31f43b44-a10a-4d3f-cba6-e35236237c6b"
      },
      "source": [
        "#collapse\n",
        "params['model']['conv_1'] = 32\n",
        "callbacks = expm.prepare(params)\n",
        "\n",
        "model = get_model(params['model'])\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train[:5000], y_train[:5000],\n",
        "          **params['training'],\n",
        "          verbose=1,\n",
        "          callbacks = callbacks,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now everything is happening in /content/experiments/exp--72399506-20411437/run--20-09-04--16-13\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 1.0456 - accuracy: 0.6842 - val_loss: 0.3508 - val_accuracy: 0.9021\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 11s 267ms/step - loss: 0.3753 - accuracy: 0.8862 - val_loss: 0.2358 - val_accuracy: 0.9300\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 11s 268ms/step - loss: 0.2736 - accuracy: 0.9168 - val_loss: 0.1867 - val_accuracy: 0.9423\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9922b7d2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwhNQmOrziJD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "29457aba-31aa-48c4-a2ec-c292c881568c"
      },
      "source": [
        "!tree experiments -d"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "experiments\n",
            "├── exp--72399506-20411437\n",
            "│   └── run--20-09-04--16-13\n",
            "│       └── models\n",
            "└── exp--72399506-44712951\n",
            "    ├── run--20-09-04--16-11\n",
            "    │   └── models\n",
            "    └── run--20-09-04--16-12\n",
            "        └── models\n",
            "\n",
            "8 directories\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}